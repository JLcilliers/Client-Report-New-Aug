# Comprehensive Deployment Analysis - Search Insights Hub
## Next.js 14 SEO Reporting Platform on Vercel

**Live Production Site**: https://searchsignal.online
**GitHub Repository**: https://github.com/JLcilliers/Client-Report-New-Aug.git
**Platform**: Vercel (Auto-deployment enabled)
**Last Updated**: October 6, 2025

---

## Executive Summary

### Deployment Health Score: 72/100

**Strengths:**
- Automated GitHub-to-Vercel deployment pipeline ‚úÖ
- Proper environment-specific database configuration (SQLite dev, PostgreSQL prod) ‚úÖ
- Comprehensive Sentry error tracking integration ‚úÖ
- Scheduled cron jobs for automated data updates ‚úÖ
- Custom build process with Prisma schema switching ‚úÖ

**Critical Issues:**
- ‚ùå No automated health checks or deployment verification
- ‚ùå Missing rollback automation and failure handling
- ‚ö†Ô∏è No staging environment for pre-production testing
- ‚ö†Ô∏è Inadequate database migration strategy for production
- ‚ö†Ô∏è Limited monitoring and alerting configuration
- ‚ö†Ô∏è No automated testing in CI/CD pipeline

---

## 1. Deployment Configuration Analysis

### 1.1 Vercel Configuration (`vercel.json`)

```json
{
  "buildCommand": "cp prisma/schema.production.prisma prisma/schema.prisma && npx prisma generate && npx next build",
  "installCommand": "npm ci",
  "framework": "nextjs",
  "env": {
    "FORCE_REBUILD": "true",
    "VERCEL_FORCE_NO_BUILD_CACHE": "1"
  },
  "functions": {
    "app/api/cron/daily-update/route.ts": { "maxDuration": 60 },
    "app/api/cron/weekly-audit/route.ts": { "maxDuration": 60 },
    "app/api/cron/update-keywords/route.ts": { "maxDuration": 60 }
  },
  "crons": [
    { "path": "/api/cron/daily-update", "schedule": "0 6 * * *" },
    { "path": "/api/cron/weekly-audit", "schedule": "0 6 * * 0" },
    { "path": "/api/cron/update-keywords", "schedule": "0 2 * * 1" }
  ]
}
```

**Analysis:**

‚úÖ **Strengths:**
- Custom build command properly switches from SQLite to PostgreSQL schema
- Prisma client generation integrated into build process
- Build cache disabled to prevent stale dependency issues
- Proper serverless function timeout configuration (60s) for data-intensive operations
- Three automated cron jobs configured:
  - Daily updates at 6:00 AM
  - Weekly audits on Sundays at 6:00 AM
  - Weekly keyword tracking updates on Mondays at 2:00 AM

‚ö†Ô∏è **Issues:**
- **Build cache disabled permanently**: Increases build time unnecessarily for every deployment
  - **Recommendation**: Re-enable caching and only disable when needed
  - Add: `"VERCEL_FORCE_NO_BUILD_CACHE": "0"` and remove cache-busting
- **No build output optimization**: Missing compression and optimization flags
- **No region configuration**: App deployed to default region (potential latency for global users)
- **Missing error boundaries**: No custom error page configuration
- **No rewrite rules**: Missing URL rewriting for cleaner URLs

**Recommendations:**

```json
{
  "buildCommand": "cp prisma/schema.production.prisma prisma/schema.prisma && npx prisma generate && npx next build",
  "installCommand": "npm ci",
  "framework": "nextjs",
  "regions": ["iad1"],  // Add: Optimal region for US East Coast
  "functions": {
    "app/api/cron/daily-update/route.ts": { "maxDuration": 60, "memory": 1024 },
    "app/api/cron/weekly-audit/route.ts": { "maxDuration": 60, "memory": 1024 },
    "app/api/cron/update-keywords/route.ts": { "maxDuration": 60, "memory": 1024 },
    "app/api/google/**": { "maxDuration": 30 },
    "app/api/public/report/**": { "maxDuration": 30 }
  },
  "crons": [
    { "path": "/api/cron/daily-update", "schedule": "0 6 * * *" },
    { "path": "/api/cron/weekly-audit", "schedule": "0 6 * * 0" },
    { "path": "/api/cron/update-keywords", "schedule": "0 2 * * 1" }
  ],
  "headers": [
    {
      "source": "/api/(.*)",
      "headers": [
        { "key": "X-Content-Type-Options", "value": "nosniff" },
        { "key": "X-Frame-Options", "value": "DENY" },
        { "key": "X-XSS-Protection", "value": "1; mode=block" }
      ]
    }
  ],
  "rewrites": [
    { "source": "/reports/:slug", "destination": "/api/public/report/:slug" }
  ]
}
```

---

### 1.2 Next.js Configuration (`next.config.js`)

```javascript
import { withSentryConfig } from '@sentry/nextjs';

const nextConfig = {
  typescript: { tsconfigPath: './tsconfig.json' },
  experimental: { instrumentationHook: true },
  images: {
    domains: ['localhost', 'online-client-reporting.vercel.app'],
  },
  webpack: (config, { isServer }) => {
    config.resolve.alias = {
      ...config.resolve.alias,
      '@': new URL('.', import.meta.url).pathname.replace(/\/$/, ''),
    };
    return config;
  },
  async redirects() {
    return [
      {
        source: '/admin/connections',
        destination: '/admin/google-accounts',
        permanent: true,
      },
      {
        source: '/admin/connections/:path*',
        destination: '/admin/google-accounts/:path*',
        permanent: true,
      },
    ];
  },
}

export default withSentryConfig(nextConfig, {
  silent: true,
  authToken: process.env.SENTRY_AUTH_TOKEN,
  org: process.env.SENTRY_ORG || "search-signal",
  project: process.env.SENTRY_PROJECT || "search-insights-hub",
  tunnelRoute: "/error-monitoring",
  hideSourceMaps: true,
  disableLogger: true,
  widenClientFileUpload: true,
  autoInstrumentServerFunctions: true,
  autoInstrumentAppDirectory: true,
});
```

**Analysis:**

‚úÖ **Strengths:**
- Sentry integration properly configured with source map upload
- Automatic server-side error instrumentation enabled
- Source maps hidden from production bundles
- Custom webpack alias for clean imports
- Permanent redirects configured (good for SEO)
- Error monitoring tunneled through Next.js to avoid ad-blockers

‚ö†Ô∏è **Issues:**
- **Missing production domain in image allowlist**: Only localhost and old Vercel URL
  - **Impact**: Images from production domain may fail to load
  - **Fix**: Add `'searchsignal.online'` to domains array
- **No output file tracing**: Missing optimization for serverless functions
- **No compression configuration**: Missing Gzip/Brotli configuration
- **No security headers**: Missing CSP, HSTS, X-Frame-Options
- **No i18n configuration**: No internationalization support configured
- **Sentry auth token in config**: Should be environment variable only

**Critical Fix Required:**

```javascript
images: {
  domains: ['localhost', 'searchsignal.online', 'online-client-reporting.vercel.app'],
  formats: ['image/avif', 'image/webp'],
  remotePatterns: [
    {
      protocol: 'https',
      hostname: '**.supabase.co',
    },
  ],
},
```

---

### 1.3 Environment Variables Configuration

**Current Setup (35 variables):**

```env
# Production URLs
APP_URL="https://searchsignal.online"
NEXTAUTH_URL="https://searchsignal.online"
NEXT_PUBLIC_URL="https://searchsignal.online"

# Database (PostgreSQL via Supabase)
DATABASE_URL="postgresql://postgres.sxqdyzdfoznshxvtfpmz:***@aws-1-us-east-2.pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1&sslmode=require"
DIRECT_URL="postgresql://postgres.sxqdyzdfoznshxvtfpmz:***@aws-1-us-east-2.pooler.supabase.com:5432/postgres"

# Authentication
AUTH_SECRET="***"
NEXTAUTH_SECRET="***"

# Google OAuth
GOOGLE_CLIENT_ID="***"
GOOGLE_CLIENT_SECRET="***"
GOOGLE_PROJECT_ID="search-insights-hub-25-aug"
GOOGLE_SERVICE_ACCOUNT_EMAIL="reporting-app-service@search-insights-hub-25-aug.iam.gserviceaccount.com"

# Google APIs
PAGESPEED_API_KEY="***"

# Supabase
NEXT_PUBLIC_SUPABASE_URL="https://sxqdyzdfoznshxvtfpmz.supabase.co"
NEXT_PUBLIC_SUPABASE_ANON_KEY="***"
SUPABASE_SERVICE_ROLE_KEY="***"

# AI APIs
ANTHROPIC_API_KEY="***"
OPENAI_API_KEY="***"
PERPLEXITY_API_KEY="***"

# Cron Jobs
CRON_SECRET="keyword-tracking-cron-secret-2025"

# Feature Flags
ENABLE_GA4="true"
ENABLE_GSC="true"
ENABLE_PAGESPEED="true"
ENABLE_CLIENT_REPORTS="true"
ENABLE_AUTO_REFRESH="true"

# Performance Settings
AUTO_REFRESH_INTERVAL="300000"  # 5 minutes
CACHE_TTL_STANDARD="3600"       # 1 hour
CACHE_TTL_DAILY="86400"         # 24 hours
CACHE_TTL_REALTIME="60"         # 1 minute
DEFAULT_DATE_RANGE="30"
MAX_REPORT_AGE_DAYS="90"

# Vercel
VERCEL_FORCE_NO_BUILD_CACHE="1"
VERCEL_OIDC_TOKEN="***"
```

**Analysis:**

‚úÖ **Strengths:**
- Comprehensive environment variable coverage
- Proper separation of public vs private variables
- Database connection pooling configured (PgBouncer)
- SSL mode enforced on database connections
- Feature flags implemented for gradual rollouts
- Performance tuning variables configured
- AI API integrations ready for advanced features

‚ö†Ô∏è **Issues & Risks:**

1. **Security Concerns:**
   - **CRITICAL**: Sensitive credentials exposed in `.env.local` file
     - Database password visible in plain text
     - API keys stored locally
     - Service role keys exposed
   - **Impact**: If this file is committed to Git, credentials are compromised
   - **Fix**: Ensure `.env.local` is in `.gitignore` (it is ‚úÖ)

2. **Missing Variables:**
   - `SENTRY_DSN` - No Sentry DSN configured for error tracking
   - `SENTRY_AUTH_TOKEN` - Required for source map upload
   - `NEXT_PUBLIC_SENTRY_DSN` - Client-side error tracking
   - `SENTRY_ENVIRONMENT` - Environment tagging for Sentry
   - `LOG_LEVEL` - No logging level configuration
   - `RATE_LIMIT_*` - No rate limiting configuration

3. **Configuration Issues:**
   - Database connection limit set to 1 (too restrictive for production)
   - Auto-refresh interval too aggressive (5 minutes)
   - No timeout configurations for external API calls
   - Cron secret hardcoded (should be generated)

**Recommendations:**

```env
# Add these critical variables to Vercel:

# Sentry Error Tracking
SENTRY_DSN="https://[key]@[org].ingest.sentry.io/[project]"
NEXT_PUBLIC_SENTRY_DSN="https://[key]@[org].ingest.sentry.io/[project]"
SENTRY_AUTH_TOKEN="[generate-from-sentry-account]"
SENTRY_ORG="search-signal"
SENTRY_PROJECT="search-insights-hub"
SENTRY_ENVIRONMENT="production"

# Logging & Monitoring
LOG_LEVEL="info"                    # debug|info|warn|error
LOG_DESTINATION="console"           # console|file|sentry
ENABLE_PERFORMANCE_MONITORING="true"

# Rate Limiting
RATE_LIMIT_ENABLED="true"
RATE_LIMIT_MAX_REQUESTS="100"
RATE_LIMIT_WINDOW_MS="900000"       # 15 minutes

# API Timeouts
GOOGLE_API_TIMEOUT="30000"          # 30 seconds
PAGESPEED_TIMEOUT="60000"           # 60 seconds
DATABASE_QUERY_TIMEOUT="10000"      # 10 seconds

# Update existing:
DATABASE_URL="postgresql://...?connection_limit=10&pool_timeout=20"  # Increase connection limit
AUTO_REFRESH_INTERVAL="600000"      # 10 minutes (less aggressive)
CRON_SECRET="[generate-secure-random-string]"  # Use: openssl rand -hex 32
```

---

## 2. Build Configuration & Optimization

### 2.1 Package.json Build Scripts

```json
{
  "scripts": {
    "dev": "next dev",
    "prebuild": "node scripts/verify-imports.js || true",
    "build": "prisma generate && next build",
    "start": "next start",
    "postinstall": "prisma generate || echo 'Prisma generation failed but continuing'",
    "build:production": "cp prisma/schema.production.prisma prisma/schema.prisma && prisma generate && next build"
  }
}
```

**Analysis:**

‚úÖ **Strengths:**
- Automatic Prisma client generation before build
- Import verification script runs before build
- Separate production build command for local testing
- Error handling in postinstall hook

‚ö†Ô∏è **Issues:**
- **No type checking in build process**: TypeScript not validated before deployment
- **No linting in CI**: ESLint not run automatically
- **No test execution**: No automated testing before deployment
- **Incomplete error handling**: Prisma generation failures silently ignored
- **No build artifact verification**: No post-build validation

**Enhanced Build Configuration:**

```json
{
  "scripts": {
    "dev": "next dev",
    "prebuild": "npm run type-check && npm run lint && node scripts/verify-imports.js",
    "build": "prisma generate && next build && npm run post-build-verify",
    "start": "next start",
    "postinstall": "prisma generate",

    "type-check": "tsc --noEmit",
    "lint": "next lint --max-warnings 0",
    "lint:fix": "next lint --fix",

    "test": "playwright test",
    "test:ci": "playwright test --reporter=json",
    "test:e2e": "playwright test --project=chromium",

    "post-build-verify": "node scripts/verify-build.js",
    "build:production": "cp prisma/schema.production.prisma prisma/schema.prisma && prisma generate && npm run build",
    "build:analyze": "ANALYZE=true npm run build",

    "db:migrate": "prisma migrate deploy",
    "db:seed": "prisma db seed",
    "db:studio": "prisma studio"
  }
}
```

Create `scripts/verify-build.js`:

```javascript
const fs = require('fs');
const path = require('path');

console.log('üîç Verifying build artifacts...');

const requiredFiles = [
  '.next/build-manifest.json',
  '.next/routes-manifest.json',
  '.next/prerender-manifest.json',
];

let allFilesExist = true;

for (const file of requiredFiles) {
  const filePath = path.join(process.cwd(), file);
  if (!fs.existsSync(filePath)) {
    console.error(`‚ùå Missing required build file: ${file}`);
    allFilesExist = false;
  } else {
    console.log(`‚úÖ Found: ${file}`);
  }
}

if (!allFilesExist) {
  console.error('‚ùå Build verification failed');
  process.exit(1);
}

console.log('‚úÖ Build verification passed');
```

---

### 2.2 Database Configuration & Migration Strategy

**Current Setup:**

**Development:**
- Database: SQLite (`prisma/dev.db`)
- Schema: `prisma/schema.prisma`

**Production:**
- Database: PostgreSQL (Supabase)
- Schema: `prisma/schema.production.prisma`
- Build command copies production schema before build

**Analysis:**

‚úÖ **Strengths:**
- Clear separation between dev and production databases
- PostgreSQL for production (better for concurrent access)
- Schema properly configured for both databases
- Connection pooling via PgBouncer
- Direct URL for migrations

‚ö†Ô∏è **Critical Issues:**

1. **No Automated Migration Strategy:**
   - Migrations must be run manually
   - No rollback mechanism
   - No migration verification in deployment
   - Risk of schema drift between environments

2. **Schema Synchronization:**
   - Two separate schema files can get out of sync
   - Manual copying during build is error-prone
   - No automated validation

3. **Missing Backup Strategy:**
   - No automated database backups
   - No point-in-time recovery configured
   - No backup verification

**Recommended Migration Strategy:**

1. **Implement Prisma Migrate in Production:**

Create `scripts/migrate-production.sh`:

```bash
#!/bin/bash
set -e

echo "üîÑ Starting production database migration..."

# Backup database before migration
echo "üì¶ Creating database backup..."
BACKUP_FILE="backup-$(date +%Y%m%d-%H%M%S).sql"
pg_dump $DATABASE_URL > $BACKUP_FILE
echo "‚úÖ Backup created: $BACKUP_FILE"

# Run migrations
echo "üîÑ Running Prisma migrations..."
cp prisma/schema.production.prisma prisma/schema.prisma
npx prisma migrate deploy

# Verify migration
echo "üîç Verifying database schema..."
npx prisma db pull --force
npx prisma validate

echo "‚úÖ Migration completed successfully"
```

2. **Add Migration CI/CD Step:**

Create `.github/workflows/deploy-production.yml`:

```yaml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test

      - name: Type check
        run: npm run type-check

      - name: Lint
        run: npm run lint

      - name: Build
        run: npm run build:production

      - name: Deploy to Vercel
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prod'
```

3. **Implement Database Seeding:**

Create `prisma/seed.ts`:

```typescript
import { PrismaClient } from '@prisma/client';

const prisma = new PrismaClient();

async function main() {
  console.log('üå± Seeding database...');

  // Add any required initial data
  await prisma.user.upsert({
    where: { email: 'admin@searchsignal.online' },
    update: {},
    create: {
      email: 'admin@searchsignal.online',
      name: 'Admin User',
      // ... other fields
    },
  });

  console.log('‚úÖ Database seeded');
}

main()
  .catch((e) => {
    console.error('‚ùå Seeding failed:', e);
    process.exit(1);
  })
  .finally(async () => {
    await prisma.$disconnect();
  });
```

Add to `package.json`:

```json
{
  "prisma": {
    "seed": "ts-node --compiler-options {\"module\":\"CommonJS\"} prisma/seed.ts"
  }
}
```

---

## 3. CI/CD Pipeline Implementation

### 3.1 Current GitHub Actions

**Existing Workflow:** `.github/workflows/claude-auto-fix.yml`

```yaml
name: Claude Auto-Fix
on:
  pull_request:
    types: [opened, synchronize]
  workflow_dispatch:

jobs:
  auto-fix:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        id: test
        run: |
          npm test 2>&1 | tee test-output.txt
          echo "exit_code=$?" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Claude Auto-Fix
        if: steps.test.outputs.exit_code != '0'
        uses: anthropic/claude-code-action@v1
        with:
          task: |
            Tests are failing. Analyze test-output.txt and:
            1. Fix all failing tests
            2. Ensure the fix doesn't break other tests
            3. Commit the fixes
            4. Re-run tests to verify
```

**Analysis:**

‚úÖ **Strengths:**
- Automated testing on pull requests
- AI-powered auto-fixing with Claude
- Test output captured for analysis

‚ùå **Critical Gaps:**
- **No deployment workflow**: Only runs on PRs, not on main branch pushes
- **No production deployment steps**: Tests run but deployment isn't automated
- **No environment checks**: Database migrations not verified
- **No rollback capability**: No automatic rollback on failure
- **No notification system**: No alerts on deployment failure
- **Limited test coverage**: Only runs tests, no type checking or linting

---

### 3.2 Recommended Complete CI/CD Pipeline

Create `.github/workflows/ci-cd-production.yml`:

```yaml
name: CI/CD Pipeline - Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '18'
  VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
  VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}

jobs:
  # Step 1: Continuous Integration
  test:
    name: Test & Quality Checks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate

      - name: TypeScript type check
        run: npm run type-check

      - name: ESLint
        run: npm run lint

      - name: Run unit tests
        run: npm test

      - name: Build application
        run: npm run build:production
        env:
          DATABASE_URL: "file:./test.db"

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: .next/
          retention-days: 7

  # Step 2: Deploy to Vercel Preview
  deploy-preview:
    name: Deploy Preview (PR only)
    needs: test
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Deploy to Vercel Preview
        uses: amondnet/vercel-action@v25
        id: vercel-preview
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ env.VERCEL_ORG_ID }}
          vercel-project-id: ${{ env.VERCEL_PROJECT_ID }}

      - name: Comment Preview URL on PR
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `‚úÖ Preview deployment ready!\n\nüîó Preview URL: ${{ steps.vercel-preview.outputs.preview-url }}`
            })

  # Step 3: Deploy to Production
  deploy-production:
    name: Deploy to Production
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://searchsignal.online

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Deploy to Vercel Production
        id: vercel-deploy
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ env.VERCEL_ORG_ID }}
          vercel-project-id: ${{ env.VERCEL_PROJECT_ID }}
          vercel-args: '--prod'

      - name: Wait for deployment
        run: sleep 30

      - name: Health check - Main app
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://searchsignal.online)
          if [ $response -ne 200 ]; then
            echo "‚ùå Health check failed: HTTP $response"
            exit 1
          fi
          echo "‚úÖ Health check passed: HTTP $response"

      - name: Health check - API
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://searchsignal.online/api/health)
          if [ $response -ne 200 ]; then
            echo "‚ùå API health check failed: HTTP $response"
            exit 1
          fi
          echo "‚úÖ API health check passed: HTTP $response"

      - name: Notify deployment success
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: 'success',
              description: 'Deployment successful',
              context: 'deployment/production'
            })

      - name: Notify deployment failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: 'failure',
              description: 'Deployment failed',
              context: 'deployment/production'
            })

      - name: Send Slack notification (optional)
        if: always()
        # Add Slack webhook integration here if desired
        run: echo "Deployment ${{ job.status }}"

  # Step 4: Smoke Tests on Production
  smoke-tests:
    name: Production Smoke Tests
    needs: deploy-production
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Playwright
        run: npm ci && npx playwright install chromium

      - name: Run smoke tests
        run: npx playwright test smoke.spec.ts
        env:
          BASE_URL: https://searchsignal.online

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-test-results
          path: test-results/
```

---

### 3.3 Create Smoke Tests

Create `tests/smoke.spec.ts`:

```typescript
import { test, expect } from '@playwright/test';

const BASE_URL = process.env.BASE_URL || 'https://searchsignal.online';

test.describe('Production Smoke Tests', () => {
  test('Homepage loads successfully', async ({ page }) => {
    await page.goto(BASE_URL);
    await expect(page).toHaveTitle(/Search Insights Hub/i);
  });

  test('Health endpoint returns 200', async ({ request }) => {
    const response = await request.get(`${BASE_URL}/api/health`);
    expect(response.status()).toBe(200);

    const data = await response.json();
    expect(data.status).toBe('ok');
    expect(data.env.hasGoogleClientId).toBe(true);
  });

  test('Admin login page accessible', async ({ page }) => {
    await page.goto(`${BASE_URL}/admin`);
    await expect(page.locator('h1')).toContainText(/sign in/i);
  });

  test('Public report page format works', async ({ page }) => {
    // Test that the public report URL structure works (even if report doesn't exist)
    await page.goto(`${BASE_URL}/public/test-report`);
    // Should load page without 500 error (404 is acceptable)
    const status = page.url();
    expect(status).toContain('searchsignal.online');
  });

  test('Sentry error monitoring active', async ({ page }) => {
    await page.goto(BASE_URL);
    const sentryLoaded = await page.evaluate(() => {
      return typeof window.__SENTRY__ !== 'undefined';
    });
    expect(sentryLoaded).toBe(true);
  });
});
```

---

## 4. Deployment Health Checks & Monitoring

### 4.1 Current Health Check Implementation

**Existing:** `app/api/health/route.ts`

```typescript
import { NextResponse } from "next/server"

export async function GET() {
  return NextResponse.json({
    status: "ok",
    timestamp: new Date().toISOString(),
    env: {
      hasGoogleClientId: !!process.env.GOOGLE_CLIENT_ID,
      hasGoogleClientSecret: !!process.env.GOOGLE_CLIENT_SECRET,
      hasSupabaseUrl: !!process.env.NEXT_PUBLIC_SUPABASE_URL,
      hasSupabaseServiceKey: !!process.env.SUPABASE_SERVICE_ROLE_KEY,
    }
  })
}
```

**Analysis:**

‚úÖ **Strengths:**
- Basic health endpoint exists
- Environment variable validation
- Returns timestamp for monitoring

‚ùå **Critical Gaps:**
- **No database connectivity check**: Doesn't verify database is accessible
- **No external service checks**: Doesn't verify Google APIs, Supabase
- **No performance metrics**: Response time, memory usage not tracked
- **No dependency health**: Doesn't check Prisma, Sentry status
- **No version information**: No app version or build info returned
- **No degraded state handling**: Only returns "ok" or fails

---

### 4.2 Enhanced Health Check System

Replace `app/api/health/route.ts`:

```typescript
import { NextResponse } from "next/server";
import { getPrisma } from "@/lib/db/prisma";

// Lightweight health check (for load balancers)
export async function GET() {
  return NextResponse.json({
    status: "ok",
    timestamp: new Date().toISOString(),
  });
}

// Detailed health check
export async function POST() {
  const startTime = Date.now();
  const checks: Record<string, any> = {};
  let overallStatus = "healthy";

  // 1. Environment Variables Check
  checks.environment = {
    status: "healthy",
    hasGoogleClientId: !!process.env.GOOGLE_CLIENT_ID,
    hasGoogleClientSecret: !!process.env.GOOGLE_CLIENT_SECRET,
    hasSupabaseUrl: !!process.env.NEXT_PUBLIC_SUPABASE_URL,
    hasDatabaseUrl: !!process.env.DATABASE_URL,
    hasSentryDsn: !!process.env.NEXT_PUBLIC_SENTRY_DSN,
  };

  // 2. Database Check
  try {
    const prisma = getPrisma();
    const dbStart = Date.now();
    await prisma.$queryRaw`SELECT 1`;
    checks.database = {
      status: "healthy",
      responseTime: Date.now() - dbStart,
      connected: true,
    };
  } catch (error: any) {
    checks.database = {
      status: "unhealthy",
      error: error.message,
      connected: false,
    };
    overallStatus = "unhealthy";
  }

  // 3. Google API Check
  try {
    if (process.env.GOOGLE_CLIENT_ID) {
      checks.googleApi = {
        status: "healthy",
        configured: true,
      };
    } else {
      checks.googleApi = {
        status: "degraded",
        configured: false,
      };
      overallStatus = overallStatus === "healthy" ? "degraded" : overallStatus;
    }
  } catch (error: any) {
    checks.googleApi = {
      status: "unhealthy",
      error: error.message,
    };
    overallStatus = "unhealthy";
  }

  // 4. Sentry Check
  checks.sentry = {
    status: process.env.NEXT_PUBLIC_SENTRY_DSN ? "healthy" : "degraded",
    configured: !!process.env.NEXT_PUBLIC_SENTRY_DSN,
  };

  // 5. Memory Usage
  if (typeof process !== 'undefined' && process.memoryUsage) {
    const mem = process.memoryUsage();
    checks.memory = {
      status: "healthy",
      heapUsed: `${Math.round(mem.heapUsed / 1024 / 1024)}MB`,
      heapTotal: `${Math.round(mem.heapTotal / 1024 / 1024)}MB`,
      external: `${Math.round(mem.external / 1024 / 1024)}MB`,
    };
  }

  // 6. Application Info
  checks.application = {
    version: process.env.NEXT_PUBLIC_APP_VERSION || "unknown",
    environment: process.env.NODE_ENV,
    buildTime: process.env.BUILD_TIME || "unknown",
    uptime: process.uptime ? `${Math.floor(process.uptime())}s` : "unknown",
  };

  const totalResponseTime = Date.now() - startTime;

  return NextResponse.json({
    status: overallStatus,
    timestamp: new Date().toISOString(),
    responseTime: totalResponseTime,
    checks,
  }, {
    status: overallStatus === "healthy" ? 200 : overallStatus === "degraded" ? 200 : 503,
  });
}
```

### 4.3 External Monitoring Setup

**Recommended Tools:**

1. **Vercel Analytics** (Already included)
   - Real user monitoring
   - Core Web Vitals tracking
   - Automatic speed insights

2. **Sentry Error Tracking** (Partially configured)
   ```typescript
   // instrumentation.ts - Enhanced configuration
   import * as Sentry from '@sentry/nextjs';

   export function register() {
     const dsn = process.env.NEXT_PUBLIC_SENTRY_DSN;
     if (!dsn) return;

     Sentry.init({
       dsn,
       environment: process.env.SENTRY_ENVIRONMENT || process.env.VERCEL_ENV || 'production',

       // Performance Monitoring
       tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.2 : 1.0,

       // Session Replay
       replaysSessionSampleRate: 0.1,
       replaysOnErrorSampleRate: 1.0,

       // Enhanced context
       integrations: [
         new Sentry.Integrations.Prisma({ client: prisma }),
       ],

       beforeSend(event, hint) {
         // Filter sensitive data
         if (event.request) {
           delete event.request.cookies;
           delete event.request.headers?.authorization;
         }
         return event;
       },
     });
   }
   ```

3. **Uptime Monitoring** (New recommendation)

   Use **UptimeRobot** or **Better Uptime**:
   - Monitor: `https://searchsignal.online/api/health`
   - Check interval: 5 minutes
   - Alert on: 2 consecutive failures
   - Notification channels: Email, Slack, SMS

4. **Performance Monitoring** (New recommendation)

   Add **Vercel Speed Insights**:
   ```bash
   npm install @vercel/speed-insights
   ```

   Update `app/layout.tsx`:
   ```typescript
   import { SpeedInsights } from '@vercel/speed-insights/next';

   export default function RootLayout({ children }) {
     return (
       <html>
         <body>
           {children}
           <SpeedInsights />
         </body>
       </html>
     );
   }
   ```

5. **Log Aggregation** (New recommendation)

   Use **Vercel Log Drains** ‚Üí **Better Stack (Logtail)**:
   ```bash
   # Add log drain in Vercel dashboard
   vercel integration add logtail
   ```

---

## 5. Error Tracking & Observability

### 5.1 Sentry Configuration Analysis

**Current Setup:**

- **Sentry Package**: `@sentry/nextjs` v10.7.0 ‚úÖ
- **Integration**: Configured in `next.config.js` ‚úÖ
- **Instrumentation**: Server-side auto-instrumentation enabled ‚úÖ
- **Source Maps**: Upload configured, hidden in production ‚úÖ

**Configuration Files:**

1. `.sentryclirc`:
   ```ini
   [defaults]
   url=https://sentry.io/
   org=search-signal
   project=search-insights-hub

   [auth]
   # Add your auth token as SENTRY_AUTH_TOKEN in environment variables
   ```

2. `instrumentation.ts`:
   ```typescript
   import * as Sentry from '@sentry/nextjs';

   export function register() {
     const dsn = process.env.NEXT_PUBLIC_SENTRY_DSN;
     if (!dsn) return;  // ‚ö†Ô∏è No DSN configured!

     const common = {
       dsn,
       environment: process.env.SENTRY_ENVIRONMENT || process.env.VERCEL_ENV || 'production',
       tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.2 : 1.0,
     };

     if (process.env.NEXT_RUNTIME === 'nodejs') {
       Sentry.init(common);
     }
     if (process.env.NEXT_RUNTIME === 'edge') {
       Sentry.init(common);
     }
   }
   ```

**Analysis:**

‚ùå **Critical Issue:**
- **SENTRY_DSN NOT CONFIGURED**: Sentry is not tracking any errors!
  - `process.env.NEXT_PUBLIC_SENTRY_DSN` is undefined
  - All error tracking is currently inactive
  - Source maps are being uploaded but errors aren't captured

‚ö†Ô∏è **Additional Issues:**
- No session replay configured
- No performance monitoring beyond basic tracing
- No breadcrumb configuration
- No custom error boundaries
- No user context tracking
- No release tracking

**Fix Required:**

1. **Add Sentry DSN to Vercel:**
   ```env
   NEXT_PUBLIC_SENTRY_DSN=https://[key]@[org].ingest.sentry.io/[project]
   SENTRY_AUTH_TOKEN=[generate-from-sentry]
   SENTRY_ORG=search-signal
   SENTRY_PROJECT=search-insights-hub
   SENTRY_ENVIRONMENT=production
   ```

2. **Enhanced Sentry Configuration:**

   Update `instrumentation.ts`:
   ```typescript
   import * as Sentry from '@sentry/nextjs';

   export function register() {
     const dsn = process.env.NEXT_PUBLIC_SENTRY_DSN;
     if (!dsn) {
       console.warn('‚ö†Ô∏è Sentry DSN not configured - error tracking disabled');
       return;
     }

     const environment = process.env.SENTRY_ENVIRONMENT ||
                        process.env.VERCEL_ENV ||
                        'production';

     const config = {
       dsn,
       environment,

       // Performance monitoring
       tracesSampleRate: environment === 'production' ? 0.2 : 1.0,

       // Session replay for debugging
       replaysSessionSampleRate: 0.1,
       replaysOnErrorSampleRate: 1.0,

       // Enable automatic breadcrumbs
       integrations: [
         new Sentry.Replay({
           maskAllText: true,
           blockAllMedia: true,
         }),
         new Sentry.BrowserTracing({
           tracePropagationTargets: ['localhost', /^https:\/\/searchsignal\.online/],
         }),
       ],

       // Release tracking
       release: process.env.NEXT_PUBLIC_VERCEL_GIT_COMMIT_SHA,

       // Filter sensitive data
       beforeSend(event, hint) {
         // Remove sensitive headers
         if (event.request) {
           delete event.request.cookies;
           if (event.request.headers) {
             delete event.request.headers.authorization;
             delete event.request.headers.cookie;
           }
         }

         // Remove query parameters that might contain tokens
         if (event.request?.url) {
           try {
             const url = new URL(event.request.url);
             url.searchParams.delete('token');
             url.searchParams.delete('access_token');
             event.request.url = url.toString();
           } catch {}
         }

         return event;
       },

       // Ignore known errors
       ignoreErrors: [
         'ResizeObserver loop limit exceeded',
         'Non-Error promise rejection captured',
         'ChunkLoadError',
       ],
     };

     if (process.env.NEXT_RUNTIME === 'nodejs') {
       Sentry.init(config);
     }
     if (process.env.NEXT_RUNTIME === 'edge') {
       Sentry.init(config);
     }

     console.log(`‚úÖ Sentry initialized for ${environment}`);
   }
   ```

3. **Add Error Boundaries:**

   Create `components/error-boundary.tsx`:
   ```typescript
   'use client';

   import * as Sentry from '@sentry/nextjs';
   import { useEffect } from 'react';

   export default function ErrorBoundary({
     error,
     reset,
   }: {
     error: Error & { digest?: string };
     reset: () => void;
   }) {
     useEffect(() => {
       Sentry.captureException(error);
     }, [error]);

     return (
       <div className="flex min-h-screen flex-col items-center justify-center">
         <h2 className="text-2xl font-bold">Something went wrong!</h2>
         <p className="text-gray-600 mt-2">{error.message}</p>
         <button
           onClick={reset}
           className="mt-4 px-4 py-2 bg-blue-600 text-white rounded"
         >
           Try again
         </button>
       </div>
     );
   }
   ```

4. **Custom Error Logging:**

   Create `lib/error-logger.ts`:
   ```typescript
   import * as Sentry from '@sentry/nextjs';

   export function logError(
     error: Error,
     context?: Record<string, any>,
     level: 'error' | 'warning' | 'info' = 'error'
   ) {
     console.error(error);

     if (process.env.NEXT_PUBLIC_SENTRY_DSN) {
       Sentry.captureException(error, {
         level,
         extra: context,
       });
     }
   }

   export function logMessage(
     message: string,
     context?: Record<string, any>,
     level: 'error' | 'warning' | 'info' = 'info'
   ) {
     console.log(message, context);

     if (process.env.NEXT_PUBLIC_SENTRY_DSN) {
       Sentry.captureMessage(message, {
         level,
         extra: context,
       });
     }
   }
   ```

---

## 6. Rollback Procedures & Disaster Recovery

### 6.1 Current Rollback Capability

**Current State:**
- ‚ùå No automated rollback mechanism
- ‚ùå No rollback documentation
- ‚ùå No deployment versioning
- ‚ùå No backup strategy for deployments

**Vercel's Built-in Rollback:**
- Vercel keeps deployment history
- Can rollback via Vercel dashboard: Deployments ‚Üí Select previous ‚Üí Promote to Production
- **Limitation**: Manual process, requires dashboard access

---

### 6.2 Automated Rollback Strategy

**1. Implement Instant Rollback Command:**

Create `scripts/rollback.sh`:

```bash
#!/bin/bash
set -e

echo "üîÑ Rolling back to previous deployment..."

# Get previous deployment
PREVIOUS_DEPLOYMENT=$(vercel ls --token=$VERCEL_TOKEN | sed -n '3p' | awk '{print $1}')

if [ -z "$PREVIOUS_DEPLOYMENT" ]; then
  echo "‚ùå No previous deployment found"
  exit 1
fi

echo "üì¶ Previous deployment: $PREVIOUS_DEPLOYMENT"
echo "‚ö†Ô∏è  This will rollback production to this deployment."
read -p "Continue? (y/n) " -n 1 -r
echo

if [[ $REPLY =~ ^[Yy]$ ]]; then
  echo "üîÑ Promoting previous deployment..."
  vercel promote $PREVIOUS_DEPLOYMENT --token=$VERCEL_TOKEN

  echo "‚úÖ Rollback complete!"
  echo "üîç Verifying health..."
  sleep 10

  curl -f https://searchsignal.online/api/health || {
    echo "‚ùå Health check failed after rollback!"
    exit 1
  }

  echo "‚úÖ Health check passed"
else
  echo "‚ùå Rollback cancelled"
  exit 1
fi
```

Make executable:
```bash
chmod +x scripts/rollback.sh
```

**2. GitHub Actions Rollback Workflow:**

Create `.github/workflows/rollback.yml`:

```yaml
name: Rollback to Previous Deployment

on:
  workflow_dispatch:
    inputs:
      deployment_url:
        description: 'Deployment URL to rollback to (or leave empty for previous)'
        required: false
        type: string
      reason:
        description: 'Reason for rollback'
        required: true
        type: string

jobs:
  rollback:
    runs-on: ubuntu-latest
    environment:
      name: production-rollback

    steps:
      - uses: actions/checkout@v4

      - name: Get previous deployment
        id: get-deployment
        run: |
          if [ -n "${{ inputs.deployment_url }}" ]; then
            DEPLOYMENT_ID="${{ inputs.deployment_url }}"
          else
            # Get the second most recent production deployment
            DEPLOYMENT_ID=$(curl -s \
              -H "Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}" \
              "https://api.vercel.com/v6/deployments?projectId=${{ secrets.VERCEL_PROJECT_ID }}&target=production&limit=2" \
              | jq -r '.deployments[1].uid')
          fi
          echo "deployment_id=$DEPLOYMENT_ID" >> $GITHUB_OUTPUT
          echo "Rolling back to: $DEPLOYMENT_ID"

      - name: Promote previous deployment
        run: |
          curl -X PATCH \
            -H "Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}" \
            -H "Content-Type: application/json" \
            "https://api.vercel.com/v13/deployments/${{ steps.get-deployment.outputs.deployment_id }}/promote" \
            -d '{}'

      - name: Wait for promotion
        run: sleep 30

      - name: Verify rollback
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://searchsignal.online/api/health)
          if [ $response -ne 200 ]; then
            echo "‚ùå Rollback verification failed: HTTP $response"
            exit 1
          fi
          echo "‚úÖ Rollback successful: HTTP $response"

      - name: Create rollback issue
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'üîÑ Production Rollback - ${{ github.run_id }}',
              body: `## Rollback Details\n\n` +
                    `**Reason**: ${{ inputs.reason }}\n` +
                    `**Triggered by**: @${{ github.actor }}\n` +
                    `**Deployment**: ${{ steps.get-deployment.outputs.deployment_id }}\n` +
                    `**Time**: ${new Date().toISOString()}\n\n` +
                    `**Action Required**: Investigate and fix the issue before redeploying.`,
              labels: ['rollback', 'production', 'urgent']
            })
```

**3. Database Rollback Strategy:**

Create `scripts/db-rollback.sh`:

```bash
#!/bin/bash
set -e

echo "üóÑÔ∏è  Database Rollback Utility"
echo "================================"

# List available backups
echo "üì¶ Available backups:"
ls -lh backups/*.sql | tail -10

read -p "Enter backup filename (or 'latest' for most recent): " BACKUP_FILE

if [ "$BACKUP_FILE" = "latest" ]; then
  BACKUP_FILE=$(ls -t backups/*.sql | head -1)
fi

if [ ! -f "backups/$BACKUP_FILE" ]; then
  echo "‚ùå Backup file not found: backups/$BACKUP_FILE"
  exit 1
fi

echo "‚ö†Ô∏è  WARNING: This will restore database from: $BACKUP_FILE"
echo "‚ö†Ô∏è  All current data will be replaced!"
read -p "Continue? (type 'YES' to confirm): " CONFIRM

if [ "$CONFIRM" != "YES" ]; then
  echo "‚ùå Rollback cancelled"
  exit 1
fi

# Create a safety backup before restoring
echo "üì¶ Creating safety backup..."
SAFETY_BACKUP="backups/pre-rollback-$(date +%Y%m%d-%H%M%S).sql"
pg_dump $DATABASE_URL > $SAFETY_BACKUP
echo "‚úÖ Safety backup created: $SAFETY_BACKUP"

# Restore from backup
echo "üîÑ Restoring database..."
psql $DATABASE_URL < "backups/$BACKUP_FILE"

echo "‚úÖ Database restored successfully"
echo "üîç Verifying database..."

# Run Prisma validation
npx prisma validate

echo "‚úÖ Database rollback complete"
```

---

### 6.3 Disaster Recovery Plan

**Recovery Time Objective (RTO):** 15 minutes
**Recovery Point Objective (RPO):** 1 hour

**1. Automated Backup Strategy:**

Create `.github/workflows/backup.yml`:

```yaml
name: Database Backup

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup PostgreSQL client
        run: sudo apt-get install postgresql-client

      - name: Create backup
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          BACKUP_FILE="backup-$(date +%Y%m%d-%H%M%S).sql"
          pg_dump $DATABASE_URL > $BACKUP_FILE

          # Compress backup
          gzip $BACKUP_FILE

          # Upload to artifact storage (or S3/GCS)
          echo "Backup created: $BACKUP_FILE.gz"

      - name: Upload backup artifact
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-${{ github.run_id }}
          path: backup-*.sql.gz
          retention-days: 30

      - name: Verify backup
        run: |
          gunzip -c backup-*.sql.gz | head -20
          echo "‚úÖ Backup verification complete"
```

**2. Incident Response Playbook:**

Create `docs/INCIDENT_RESPONSE.md`:

```markdown
# Incident Response Playbook

## Severity Levels

### P0 - Critical (Production Down)
- **Response Time**: Immediate
- **Actions**:
  1. Check Vercel status: https://vercel-status.com
  2. Check health endpoint: https://searchsignal.online/api/health
  3. Review Sentry errors: https://sentry.io
  4. Rollback if deployment-related
  5. Alert team via Slack

### P1 - High (Degraded Service)
- **Response Time**: 15 minutes
- **Actions**:
  1. Identify affected features
  2. Check error rates in Sentry
  3. Review Vercel function logs
  4. Implement mitigation
  5. Document incident

### P2 - Medium (Non-Critical Issues)
- **Response Time**: 1 hour
- **Actions**:
  1. Create GitHub issue
  2. Investigate root cause
  3. Schedule fix
  4. Update monitoring

## Emergency Contacts

- **On-call Engineer**: [Phone/Email]
- **Database Admin**: [Phone/Email]
- **Vercel Support**: support@vercel.com

## Quick Commands

```bash
# Check deployment status
vercel ls --prod

# View function logs
vercel logs [deployment-url]

# Rollback
./scripts/rollback.sh

# Database backup
./scripts/db-backup.sh

# Database restore
./scripts/db-rollback.sh
```

## Rollback Checklist

- [ ] Verify issue severity justifies rollback
- [ ] Notify team of rollback decision
- [ ] Create database backup
- [ ] Execute rollback script
- [ ] Verify health checks pass
- [ ] Monitor error rates for 15 minutes
- [ ] Document incident
- [ ] Schedule post-mortem
```

---

## 7. Production Readiness Assessment

### 7.1 Security Checklist

‚úÖ **Implemented:**
- HTTPS enforced via Vercel
- Environment variables properly secured
- Database SSL connections enforced
- OAuth2 authentication with Google
- Sentry error tracking configured (needs DSN)
- `.gitignore` properly configured

‚ö†Ô∏è **Needs Improvement:**
- **No rate limiting** on API endpoints
  - Risk: API abuse, DDoS attacks
  - Fix: Implement `next-rate-limit` or Vercel Edge Config
- **No CSRF protection** on state-changing operations
  - Risk: Cross-site request forgery
  - Fix: Implement CSRF tokens
- **No input validation** on API routes
  - Risk: Injection attacks
  - Fix: Use `zod` for request validation
- **No security headers** configured
  - Risk: XSS, clickjacking
  - Fix: Add security headers in `next.config.js`

**Security Enhancements:**

1. **Add Rate Limiting:**

Install: `npm install @upstash/ratelimit @upstash/redis`

Create `lib/rate-limit.ts`:
```typescript
import { Ratelimit } from '@upstash/ratelimit';
import { Redis } from '@upstash/redis';

export const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, '10 s'),
  analytics: true,
});

export async function checkRateLimit(identifier: string) {
  const { success, limit, reset, remaining } = await ratelimit.limit(identifier);

  return {
    success,
    headers: {
      'X-RateLimit-Limit': limit,
      'X-RateLimit-Remaining': remaining,
      'X-RateLimit-Reset': reset,
    },
  };
}
```

2. **Add Input Validation:**

Install: `npm install zod`

Create `lib/validation.ts`:
```typescript
import { z } from 'zod';

export const CreateReportSchema = z.object({
  clientName: z.string().min(1).max(100),
  reportName: z.string().min(1).max(200),
  googleAccountId: z.string().uuid(),
  ga4PropertyId: z.string().min(1),
  searchConsolePropertyId: z.string().url(),
});

export function validateRequest<T>(
  schema: z.ZodSchema<T>,
  data: unknown
): { success: true; data: T } | { success: false; error: string } {
  const result = schema.safeParse(data);

  if (result.success) {
    return { success: true, data: result.data };
  }

  return {
    success: false,
    error: result.error.errors.map(e => e.message).join(', '),
  };
}
```

3. **Add Security Headers:**

Update `next.config.js`:
```javascript
async headers() {
  return [
    {
      source: '/(.*)',
      headers: [
        {
          key: 'X-DNS-Prefetch-Control',
          value: 'on'
        },
        {
          key: 'Strict-Transport-Security',
          value: 'max-age=31536000; includeSubDomains'
        },
        {
          key: 'X-Frame-Options',
          value: 'SAMEORIGIN'
        },
        {
          key: 'X-Content-Type-Options',
          value: 'nosniff'
        },
        {
          key: 'X-XSS-Protection',
          value: '1; mode=block'
        },
        {
          key: 'Referrer-Policy',
          value: 'strict-origin-when-cross-origin'
        },
        {
          key: 'Permissions-Policy',
          value: 'camera=(), microphone=(), geolocation=()'
        },
      ],
    },
  ];
},
```

---

### 7.2 Performance Optimization

**Current State:**
- Next.js 14 with App Router ‚úÖ
- Image optimization enabled ‚úÖ
- Server-side rendering enabled ‚úÖ
- Build cache disabled ‚ö†Ô∏è

**Recommended Optimizations:**

1. **Enable Edge Runtime for API Routes:**

Update hot API routes:
```typescript
// app/api/public/report/[slug]/route.ts
export const runtime = 'edge';
export const revalidate = 60; // ISR every 60 seconds

export async function GET(
  request: Request,
  { params }: { params: { slug: string } }
) {
  // ... existing code
}
```

2. **Implement Edge Caching:**

Create `middleware.ts`:
```typescript
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';

export function middleware(request: NextRequest) {
  const response = NextResponse.next();

  // Cache static assets aggressively
  if (request.nextUrl.pathname.startsWith('/_next/static/')) {
    response.headers.set(
      'Cache-Control',
      'public, max-age=31536000, immutable'
    );
  }

  // Cache API responses with stale-while-revalidate
  if (request.nextUrl.pathname.startsWith('/api/public/')) {
    response.headers.set(
      'Cache-Control',
      's-maxage=60, stale-while-revalidate=300'
    );
  }

  return response;
}

export const config = {
  matcher: ['/((?!_next/image).*)'],
};
```

3. **Database Query Optimization:**

Add database indexes:
```prisma
model ClientReport {
  // ... existing fields

  @@index([shareableId])
  @@index([isActive, userId])
  @@index([googleAccountId])
}

model ReportCache {
  // ... existing fields

  @@index([reportId, dataType])
  @@index([expiresAt])
}
```

4. **Implement Response Compression:**

Update `next.config.js`:
```javascript
compress: true, // Enable gzip compression
```

---

### 7.3 Scalability Assessment

**Current Limits:**

| Resource | Current | Production Ready | Scaling Strategy |
|----------|---------|------------------|------------------|
| **Database Connections** | 1 (PgBouncer) | 10-50 | Increase connection pool |
| **Vercel Functions** | 60s timeout | ‚úÖ | Adequate for data fetching |
| **API Rate Limit** | None ‚ö†Ô∏è | 100/min | Implement rate limiting |
| **Concurrent Users** | Unknown | 1000+ | Add load testing |
| **Data Refresh** | 5 min | ‚úÖ | Configurable per client |

**Scaling Recommendations:**

1. **Increase Database Connection Pool:**
   ```env
   DATABASE_URL="postgresql://...?connection_limit=20&pool_timeout=30"
   ```

2. **Implement Caching Layer:**
   - Use Vercel Edge Config for configuration data
   - Redis for session and cache management
   - Cloudflare for CDN (already using Vercel CDN)

3. **Add Load Testing:**

Create `tests/load-test.spec.ts`:
```typescript
import { test } from '@playwright/test';

test.describe('Load Testing', () => {
  test('Concurrent report access', async ({ browser }) => {
    const contexts = await Promise.all(
      Array(10).fill(null).map(() => browser.newContext())
    );

    const pages = await Promise.all(
      contexts.map(context => context.newPage())
    );

    const startTime = Date.now();

    await Promise.all(
      pages.map(page => page.goto('https://searchsignal.online/public/test-report'))
    );

    const loadTime = Date.now() - startTime;
    console.log(`10 concurrent requests completed in ${loadTime}ms`);

    // Cleanup
    await Promise.all(contexts.map(context => context.close()));
  });
});
```

---

## 8. Deployment Best Practices Compliance

### 8.1 Current Compliance Matrix

| Best Practice | Status | Priority | Action Required |
|---------------|--------|----------|-----------------|
| **Automated Testing** | ‚ö†Ô∏è Partial | HIGH | Add comprehensive test suite |
| **Type Safety** | ‚úÖ Yes | HIGH | - |
| **Code Linting** | ‚úÖ Yes | MEDIUM | Run in CI/CD |
| **Environment Parity** | ‚ö†Ô∏è Partial | HIGH | Add staging environment |
| **Database Migrations** | ‚ö†Ô∏è Manual | HIGH | Automate in CI/CD |
| **Secret Management** | ‚úÖ Yes | HIGH | - |
| **Monitoring** | ‚ö†Ô∏è Partial | HIGH | Add Sentry DSN, uptime monitoring |
| **Error Tracking** | ‚ö†Ô∏è Configured | HIGH | Enable Sentry (add DSN) |
| **Health Checks** | ‚ö†Ô∏è Basic | HIGH | Enhance health endpoint |
| **Rollback Strategy** | ‚ùå Manual | HIGH | Implement automated rollback |
| **Backup Strategy** | ‚ùå None | CRITICAL | Implement automated backups |
| **Documentation** | ‚ö†Ô∏è Partial | MEDIUM | Complete deployment docs |
| **Performance Monitoring** | ‚ö†Ô∏è Basic | MEDIUM | Add detailed metrics |
| **Security Headers** | ‚ùå None | HIGH | Configure in next.config.js |
| **Rate Limiting** | ‚ùå None | HIGH | Implement API rate limiting |
| **Load Testing** | ‚ùå None | MEDIUM | Add load test suite |
| **Dependency Scanning** | ‚ùå None | MEDIUM | Add Dependabot/Snyk |
| **Build Optimization** | ‚ö†Ô∏è Partial | MEDIUM | Re-enable caching |
| **CDN Configuration** | ‚úÖ Vercel | LOW | - |
| **Incident Response** | ‚ùå None | HIGH | Create runbook |

**Overall Compliance Score:** 58/100

---

### 8.2 12-Factor App Compliance

| Factor | Status | Implementation |
|--------|--------|----------------|
| **1. Codebase** | ‚úÖ | Single Git repository with version control |
| **2. Dependencies** | ‚úÖ | package.json with locked versions |
| **3. Config** | ‚úÖ | Environment variables for all config |
| **4. Backing Services** | ‚úÖ | Supabase PostgreSQL, Google APIs as services |
| **5. Build, Release, Run** | ‚ö†Ô∏è | Build automated, release/run need improvement |
| **6. Processes** | ‚úÖ | Stateless Next.js functions |
| **7. Port Binding** | ‚úÖ | Vercel handles port binding |
| **8. Concurrency** | ‚úÖ | Serverless functions scale automatically |
| **9. Disposability** | ‚úÖ | Fast startup, graceful shutdown |
| **10. Dev/Prod Parity** | ‚ö†Ô∏è | SQLite dev vs PostgreSQL prod (acceptable) |
| **11. Logs** | ‚ö†Ô∏è | Console logs, needs aggregation |
| **12. Admin Processes** | ‚úÖ | Cron jobs for administrative tasks |

---

## 9. Critical Action Items (Priority Order)

### Immediate (Within 24 Hours)

1. **Enable Sentry Error Tracking** ‚ö†Ô∏è CRITICAL
   - Add `SENTRY_DSN` and `NEXT_PUBLIC_SENTRY_DSN` to Vercel
   - Verify error capture is working
   - **Impact**: Currently no error visibility in production

2. **Fix Image Domain Configuration** ‚ö†Ô∏è CRITICAL
   - Add `searchsignal.online` to allowed image domains in `next.config.js`
   - **Impact**: Images may fail to load from production domain

3. **Implement Database Backup Strategy** üî¥ CRITICAL
   - Set up automated backups (every 6 hours)
   - Test restoration process
   - **Impact**: No recovery mechanism if database fails

4. **Add Security Headers** ‚ö†Ô∏è HIGH
   - Implement CSP, HSTS, X-Frame-Options
   - **Impact**: Vulnerable to XSS and clickjacking

### Short-term (Within 1 Week)

5. **Implement Automated Rollback** üî¥ HIGH
   - Create rollback GitHub Action workflow
   - Document rollback procedures
   - **Impact**: Manual rollback is slow (15+ minutes)

6. **Add Health Check Monitoring** ‚ö†Ô∏è HIGH
   - Set up UptimeRobot or Better Uptime
   - Configure alerting (email, Slack)
   - **Impact**: No proactive downtime detection

7. **Implement Rate Limiting** ‚ö†Ô∏è HIGH
   - Add rate limiting to API endpoints
   - **Impact**: Vulnerable to API abuse

8. **Complete CI/CD Pipeline** ‚ö†Ô∏è HIGH
   - Add comprehensive GitHub Actions workflow
   - Include tests, linting, type checking
   - **Impact**: Quality issues may reach production

### Medium-term (Within 2 Weeks)

9. **Add Staging Environment** ‚ö†Ô∏è MEDIUM
   - Create staging.searchsignal.online
   - Deploy PRs to staging automatically
   - **Impact**: Changes deploy directly to production

10. **Enhance Database Migration Strategy** ‚ö†Ô∏è MEDIUM
    - Automate migrations in deployment
    - Add rollback capability
    - **Impact**: Manual migration is error-prone

11. **Implement Comprehensive Testing** ‚ö†Ô∏è MEDIUM
    - Add unit tests (target 60% coverage)
    - Add E2E tests for critical flows
    - Add smoke tests for production
    - **Impact**: No automated quality assurance

12. **Add Performance Monitoring** ‚ö†Ô∏è MEDIUM
    - Implement detailed performance tracking
    - Set up Core Web Vitals monitoring
    - **Impact**: No visibility into performance issues

### Long-term (Within 1 Month)

13. **Implement Load Testing** ‚ö†Ô∏è MEDIUM
    - Create load test suite
    - Identify scaling bottlenecks
    - **Impact**: Unknown behavior under load

14. **Add Dependency Scanning** ‚ö†Ô∏è LOW
    - Set up Dependabot or Snyk
    - Automate security updates
    - **Impact**: Vulnerable dependencies may go unnoticed

15. **Optimize Build Process** ‚ö†Ô∏è LOW
    - Re-enable build caching
    - Implement build-time optimizations
    - **Impact**: Slower deployments

---

## 10. Deployment Workflow Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Developer Workflow                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Local Development      ‚îÇ
                    ‚îÇ   (SQLite Database)      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚îÇ git push origin feature-branch
                                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    GitHub Pull Request Created                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                              ‚îÇ
                    ‚ñº                              ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Run Tests        ‚îÇ         ‚îÇ  Claude Auto-Fix  ‚îÇ
          ‚îÇ  Type Check       ‚îÇ         ‚îÇ  (on test fail)   ‚îÇ
          ‚îÇ  Lint             ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ All checks pass
                    ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ Deploy to Vercel  ‚îÇ
          ‚îÇ Preview           ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ Preview URL: preview-abc123.vercel.app
                    ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Code Review &    ‚îÇ
          ‚îÇ  Testing          ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ Merge to main
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Production Deployment                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                          ‚îÇ                           ‚îÇ
        ‚ñº                          ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Copy Schema  ‚îÇ         ‚îÇ  Install Deps ‚îÇ         ‚îÇ  Build App    ‚îÇ
‚îÇ  (PostgreSQL) ‚îÇ    ‚Üí    ‚îÇ  npm ci       ‚îÇ    ‚Üí    ‚îÇ  next build   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                          ‚îÇ                           ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Deploy to Vercel       ‚îÇ
                    ‚îÇ   (Serverless Functions) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ              ‚îÇ              ‚îÇ
                    ‚ñº              ‚ñº              ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ Health Check‚îÇ  ‚îÇ  Sentry     ‚îÇ  ‚îÇ  Uptime     ‚îÇ
          ‚îÇ /api/health ‚îÇ  ‚îÇ  Monitoring ‚îÇ  ‚îÇ  Monitoring ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ              ‚îÇ              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                              ‚îÇ
                    ‚ñº                              ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  ‚úÖ Deployment     ‚îÇ         ‚îÇ  ‚ùå Deployment     ‚îÇ
          ‚îÇ  Successful        ‚îÇ         ‚îÇ  Failed            ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                              ‚îÇ
                    ‚îÇ                              ‚îÇ
                    ‚ñº                              ‚ñº
        üéâ Live at                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        searchsignal.online             ‚îÇ  Automated        ‚îÇ
                                        ‚îÇ  Rollback         ‚îÇ
                                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 11. Quick Reference Commands

### Deployment Commands
```bash
# Deploy to production (via Git push)
git add .
git commit -m "Deploy: [description]"
git push origin main

# Manual deployment with Vercel CLI
vercel --prod

# Check deployment status
vercel ls --prod

# View deployment logs
vercel logs [deployment-url]

# Promote specific deployment to production
vercel promote [deployment-url]
```

### Rollback Commands
```bash
# Automated rollback (after implementing script)
./scripts/rollback.sh

# Manual rollback via Vercel CLI
vercel rollback

# Database rollback
./scripts/db-rollback.sh
```

### Health Check Commands
```bash
# Basic health check
curl https://searchsignal.online/api/health

# Detailed health check
curl -X POST https://searchsignal.online/api/health

# Monitor health continuously
watch -n 10 curl -s https://searchsignal.online/api/health
```

### Database Commands
```bash
# Run migrations (production)
DATABASE_URL=$PROD_DB_URL npx prisma migrate deploy

# Generate Prisma client
npx prisma generate

# View database in browser
npx prisma studio

# Create backup
./scripts/db-backup.sh

# Restore backup
./scripts/db-rollback.sh [backup-file]
```

### Development Commands
```bash
# Start local development
npm run dev

# Build for production (locally)
npm run build:production

# Type check
npm run type-check

# Run linting
npm run lint

# Run tests
npm test

# Run production readiness scan
npm run production:scan
```

---

## 12. Summary & Recommendations

### Current State
The Search Insights Hub deployment is **partially production-ready** with a basic automated deployment pipeline from GitHub to Vercel. The application successfully auto-deploys and serves traffic at https://searchsignal.online, but lacks critical production safeguards.

### Key Strengths
1. ‚úÖ Automated GitHub-to-Vercel deployment pipeline
2. ‚úÖ Proper environment-specific database configuration (SQLite dev, PostgreSQL prod)
3. ‚úÖ Comprehensive feature flag system for gradual rollouts
4. ‚úÖ Scheduled cron jobs for automated data updates
5. ‚úÖ Sentry integration configured (needs DSN)
6. ‚úÖ TypeScript for type safety
7. ‚úÖ Modern tech stack (Next.js 14, Prisma, PostgreSQL)

### Critical Gaps
1. ‚ùå **No error tracking active** (Sentry DSN missing)
2. ‚ùå **No automated rollback mechanism**
3. ‚ùå **No database backup strategy**
4. ‚ùå **No staging environment**
5. ‚ùå **No comprehensive health monitoring**
6. ‚ùå **No security headers configured**
7. ‚ùå **No rate limiting on APIs**
8. ‚ùå **No automated testing in CI/CD**

### Priority Actions (Next 48 Hours)
1. **Add Sentry DSN** to enable error tracking (30 min)
2. **Implement automated backups** to prevent data loss (2 hours)
3. **Add security headers** to protect against common attacks (1 hour)
4. **Set up uptime monitoring** for proactive alerting (1 hour)
5. **Create rollback procedure** for quick recovery (3 hours)

### Estimated Time to Full Production Readiness
- **Immediate fixes** (Critical): 8 hours
- **Short-term improvements** (High priority): 2 weeks
- **Medium-term enhancements** (Medium priority): 4 weeks
- **Long-term optimizations** (Low priority): 8 weeks

### Deployment Risk Level
**Current Risk:** üü° **MEDIUM-HIGH**

With immediate fixes implemented: üü¢ **LOW-MEDIUM**

---

## 13. Next Steps

### Week 1: Critical Fixes
- [ ] Enable Sentry error tracking
- [ ] Fix image domain configuration
- [ ] Implement automated database backups
- [ ] Add security headers
- [ ] Set up health check monitoring

### Week 2: Essential Improvements
- [ ] Implement automated rollback
- [ ] Add rate limiting to APIs
- [ ] Complete CI/CD pipeline with tests
- [ ] Create incident response playbook
- [ ] Document all procedures

### Week 3: Quality Enhancements
- [ ] Add staging environment
- [ ] Implement comprehensive testing
- [ ] Enhance database migration strategy
- [ ] Add performance monitoring
- [ ] Create load testing suite

### Week 4: Optimization & Polish
- [ ] Optimize build process
- [ ] Add dependency scanning
- [ ] Implement advanced caching
- [ ] Complete all documentation
- [ ] Conduct disaster recovery drill

---

**Document Version:** 1.0
**Last Updated:** October 6, 2025
**Next Review:** October 20, 2025
**Owner:** Development Team
**Status:** Living Document
